{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.57', '1.1.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai, torch\n",
    "fastai.__version__ , torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 20 20:52:02 2019       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.116                Driver Version: 390.116                   |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   51C    P0    65W / 250W |    370MiB / 11177MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1039      G   /usr/lib/xorg/Xorg                           139MiB |\r\n",
      "|    0      2165      G   compiz                                       138MiB |\r\n",
      "|    0     32623      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     32637      G   /usr/lib/firefox/firefox                      77MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/gaurav/PycharmProjects/nlp-for-bengali/language-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.tokenizer import BengaliTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inltk.tokenizer.BengaliTokenizer"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BengaliTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BengaliTokenizer(BaseTokenizer):\n",
    "#     def __init__(self, lang:str):\n",
    "#         self.lang = lang\n",
    "#         self.sp = spm.SentencePieceProcessor()\n",
    "#         self.sp.Load(str(path/\"../tokenizer/bengali_lm.model\"))\n",
    "        \n",
    "#     def tokenizer(self, t:str) -> List[str]:\n",
    "#         return self.sp.EncodeAsPieces(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(path/\"../tokenizer/bengali_lm.model\"))\n",
    "itos = [sp.IdToPiece(int(i)) for i in range(30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30,000 is the vocab size that we chose in sentencepiece\n",
    "bengali_vocab = Vocab(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tok_func=BengaliTokenizer, lang='bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(path=path/'transformer', tokenizer=tokenizer, vocab=bengali_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>▁নদ ▁ইত্যাদি ▁নামে ▁অভিহিত ▁করা ▁যায় । ▁আবার ▁ভৌগোলিক ▁অঞ্চলভেদে ▁ছোট ▁নদী কে ▁বিভিন্ন ▁নামে ▁ডাকা ▁হয় । &lt;unk&gt; ▁m . m ori s wa এর ▁মতে ▁নদী ▁হল ▁খাতের ▁মধ ▁্য ▁দিয়ে ▁প্রবাহিত ▁জলধারা । - r ive r ▁is ▁a ▁can al ▁ flow . ▁সাধারণত ▁উঁচু ▁ভূমি ▁বা ▁পাহাড় ▁গিরিখাত ▁থেকে ▁সৃষ্ট ▁ঝরণা ধারা , ▁বরফ গল িত ▁স্রোত ▁কিংবা ▁প্রাকৃতিক ▁পরিবর্তন ▁থেকে ▁নদীর ▁জন্ম । ▁হাজার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>† p an the ra ▁z d ans ky i † ▁প্যান থে রা ▁গন টির ▁রয়েছে ▁নিম্নোক্ত ▁বাঘের ▁প্রজাতি ▁ও ▁উপপ্রজাতি গুলো । ▁প্যান থে রা ▁গন ে ▁রয়েছে ▁নিম্নোক্ত ▁সিংহের ▁প্রজাতি ▁ও ▁উপপ্রজাতি গুলো । ▁প্যান থে রা ▁গন ে ▁রয়েছে ▁নিম্নোক্ত ▁জাগ ুয়া র ের ▁প্রজাতি ▁ও ▁উপপ্রজাতি গুলো । ▁প্যান থে রা ▁গন ▁ টিতে ▁রয়েছে ▁নিম্নোক্ত ▁চিতাবাঘ ▁গুলোর ▁প্রজাতি ▁ও ▁উপপ্রজাতি গুলো । ▁বৈজ্ঞানিক ▁নাম</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>▁পরিবার ▁থেকে ▁মাংস , ▁সমৃদ্ধ ▁এবং ▁আরো ▁সম্ভ্রান্ত ▁পরিবার ▁এর ▁সাথে ▁সম্পর্কিত , ▁কুন ল ▁প্যা ট্রি সিও ▁তার ▁মা ▁ছিলেন ▁একজন ▁ধার্মিক ▁ক্যাথলিক ▁যিনি ▁তার ▁ছেলেকে ও ▁এক ▁হয়েছিলেন । ▁এছাড়াও ▁তিনি ▁গবেষণা ▁আইন ▁এ , ▁যেখানে ▁তিনি ▁তখন ▁একটি ▁অবৈধ ▁সংগঠন ▁সিএফ পি ▁যোগ ▁দেন ▁১৯৩১ ▁সালে ▁বিশ্ববিদ্যালয় ের &lt;unk&gt; ▁তার ▁ছোট ▁বোন ▁মেরি ▁মান ্যু টা ▁বার র ের ইন হাস ▁কুন হাল ▁এবং ▁তার ▁বড় ▁ভাই</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>▁দিকে , ▁আমি ▁নিশ্চিত ▁ছিলাম ▁আমি ▁রিয়াল ▁মাদ্রিদে ▁থাক ব ▁কিন্তু ▁আমি ▁দেখ লাম ▁যে ▁আমার ▁কোচ ▁ও ▁মালিকের ▁আমার ▁প্রতি ▁সেই ▁বিশ্বাস টি ▁নেই । ▁আমি ▁একজন ▁খেলোয়াড় ▁যার ▁জন্যে ▁ওই ▁বিশ্বাস টি ▁অত্যন্ত ▁গুরুত্বপূর্ণ ▁ছিল ▁যা ▁আমি ▁মনে ▁করেছি ▁আর্সেনাল ের ▁আমার ▁প্রতি ▁ছিল , ▁এটাই ▁ছিল ▁সেই ▁কারণ ▁যা ▁আমাকে ▁আর্সেনাল ে ▁আসতে ▁প্রভাবিত ▁করেছে ।\" ▁রিয়াল ▁মাদ্রিদ ের ▁অনেক ▁খেলোয়াড় ▁তার ▁এই ▁দল ▁থেকে ▁চলে ▁যাওয়ার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>▁x ▁৪০০ ▁মিটার ▁রিলে ▁ইভেন্টে ▁স্বর্ণ ▁পদক ▁জিতেছেন । ▁২৯ ▁জুন ▁২০১১ , ▁রয়টার্স ▁রিপোর্ট ▁করেন ▁যে , ▁তিনি ▁এন াবলি ক ▁স্টেরয়েড ▁মে থান ডি য়েন অন ▁এর ▁জন্য ▁ইতিবাচক ▁পরীক্ষিত ▁হয়েছে ▁এবং ▁অফ ▁সিজন ▁টেষ্ট ▁এ ▁স্ট্যান জো লো ল । ▁একই ▁দিনে ▁ভারতীয় ▁এ্যা থ লেট িক ▁ফেড ার েশান ▁ও ▁একই ▁ঘোষনা ▁দেন । ▁তিনি ▁ফলাফল ▁এর ▁জন্য ▁দায়ী ▁করেন ▁দূষিত ▁খাবার ▁কে ▁এবং ▁এই ▁রিপোর্ট</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_lm.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, TransformerXL, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): TransformerXL(\n",
       "    (encoder): Embedding(30000, 410)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop_emb): Dropout(p=0.1)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): DecoderLayer(\n",
       "        (mhra): MultiHeadRelativeAttention(\n",
       "          (attention): Linear(in_features=410, out_features=1230, bias=False)\n",
       "          (out): Linear(in_features=410, out_features=410, bias=False)\n",
       "          (drop_att): Dropout(p=0.1)\n",
       "          (drop_res): Dropout(p=0.1)\n",
       "          (ln): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          (r_attn): Linear(in_features=410, out_features=410, bias=False)\n",
       "        )\n",
       "        (ff): SequentialEx(\n",
       "          (layers): ModuleList(\n",
       "            (0): Linear(in_features=410, out_features=2100, bias=True)\n",
       "            (1): ReLU(inplace)\n",
       "            (2): Dropout(p=0.1)\n",
       "            (3): Linear(in_features=2100, out_features=410, bias=True)\n",
       "            (4): Dropout(p=0.1)\n",
       "            (5): MergeLayer()\n",
       "            (6): LayerNorm(torch.Size([410]), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=410, out_features=30000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.160033</td>\n",
       "      <td>6.114402</td>\n",
       "      <td>0.186740</td>\n",
       "      <td>35:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.363132</td>\n",
       "      <td>5.303140</td>\n",
       "      <td>0.232614</td>\n",
       "      <td>35:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.834630</td>\n",
       "      <td>4.814843</td>\n",
       "      <td>0.266739</td>\n",
       "      <td>35:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.670889</td>\n",
       "      <td>4.640143</td>\n",
       "      <td>0.276662</td>\n",
       "      <td>35:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.642864</td>\n",
       "      <td>4.578518</td>\n",
       "      <td>0.279461</td>\n",
       "      <td>35:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.518284</td>\n",
       "      <td>4.534373</td>\n",
       "      <td>0.279906</td>\n",
       "      <td>35:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.576394</td>\n",
       "      <td>4.445619</td>\n",
       "      <td>0.286890</td>\n",
       "      <td>35:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.437396</td>\n",
       "      <td>4.383281</td>\n",
       "      <td>0.291991</td>\n",
       "      <td>35:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.327770</td>\n",
       "      <td>4.280431</td>\n",
       "      <td>0.300357</td>\n",
       "      <td>35:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.343741</td>\n",
       "      <td>4.312667</td>\n",
       "      <td>0.297910</td>\n",
       "      <td>35:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.208006</td>\n",
       "      <td>4.151498</td>\n",
       "      <td>0.312441</td>\n",
       "      <td>35:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.065727</td>\n",
       "      <td>4.057003</td>\n",
       "      <td>0.323322</td>\n",
       "      <td>35:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.941578</td>\n",
       "      <td>3.969592</td>\n",
       "      <td>0.333966</td>\n",
       "      <td>35:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.823433</td>\n",
       "      <td>3.892510</td>\n",
       "      <td>0.342595</td>\n",
       "      <td>35:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.879285</td>\n",
       "      <td>3.820481</td>\n",
       "      <td>0.351674</td>\n",
       "      <td>35:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.740055</td>\n",
       "      <td>3.764005</td>\n",
       "      <td>0.359238</td>\n",
       "      <td>35:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.666404</td>\n",
       "      <td>3.720394</td>\n",
       "      <td>0.365659</td>\n",
       "      <td>35:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.520414</td>\n",
       "      <td>3.689401</td>\n",
       "      <td>0.369961</td>\n",
       "      <td>35:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.642337</td>\n",
       "      <td>3.676175</td>\n",
       "      <td>0.371686</td>\n",
       "      <td>35:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.592945</td>\n",
       "      <td>3.672997</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>35:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.18673951923847198.\n",
      "Better model found at epoch 1 with accuracy value: 0.23261427879333496.\n",
      "Better model found at epoch 2 with accuracy value: 0.2667387127876282.\n",
      "Better model found at epoch 3 with accuracy value: 0.27666205167770386.\n",
      "Better model found at epoch 4 with accuracy value: 0.2794608175754547.\n",
      "Better model found at epoch 5 with accuracy value: 0.27990642189979553.\n",
      "Better model found at epoch 6 with accuracy value: 0.2868899703025818.\n",
      "Better model found at epoch 7 with accuracy value: 0.29199138283729553.\n",
      "Better model found at epoch 8 with accuracy value: 0.30035650730133057.\n",
      "Better model found at epoch 10 with accuracy value: 0.3124406337738037.\n",
      "Better model found at epoch 11 with accuracy value: 0.3233223557472229.\n",
      "Better model found at epoch 12 with accuracy value: 0.3339662253856659.\n",
      "Better model found at epoch 13 with accuracy value: 0.34259486198425293.\n",
      "Better model found at epoch 14 with accuracy value: 0.35167354345321655.\n",
      "Better model found at epoch 15 with accuracy value: 0.3592382073402405.\n",
      "Better model found at epoch 16 with accuracy value: 0.3656591773033142.\n",
      "Better model found at epoch 17 with accuracy value: 0.36996063590049744.\n",
      "Better model found at epoch 18 with accuracy value: 0.37168627977371216.\n",
      "Better model found at epoch 19 with accuracy value: 0.37219980359077454.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(20, 1e-3, moms=(0.8,0.7), callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='accuracy', name='model')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"ফিলো লাউ\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ফিলো লাউ টাইম ▁ঢাকা তে ▁জন্ম ▁নেন । ▁তিনি ▁মূলত ▁পানি ▁ও ▁পানি ▁থেকে ▁পানি ▁উত্তোলন ▁করে ▁বিভিন্ন ▁দাতব্য ▁প্রতিষ্ঠানে ▁কৃতিত্বের ▁সাথে ▁কাজ ▁করেন । ▁তিনি ▁ব্যাপক ▁খ্যাতি ▁অর্জন ▁করেন ▁এবং ▁সেখানে ▁তিনি ▁একজন ▁ভুটান ি ▁মহিলার ▁সাথে ▁ভ্রমণ ▁করেন । ▁x\n",
      "ফিলো লাউ ▁পরিচালিত ▁একটি ▁ইসলামি ▁আরবি ▁ভাষার ▁প্রাচ্য ▁ভাষায় ▁রচিত ▁একটি ▁তুর্কি ▁তুর্কি ▁তুর্কি ▁ভাষার ▁ । ▁এটা ▁মূলত ▁একটি ▁তুর্কি ▁তুর্কি ▁ভাষা , ▁তবে ▁তা ▁ইংরেজি র ▁সাথে ▁সম্পর্কিত । ▁x x bo s ▁গৃহ ায়ন ▁বা ▁ঢ িল ে ঢ\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.9) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.369720278889915"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(3.672997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')\n",
    "learn.model.eval()\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding vectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/gaurav/PycharmProjects/nlp-for-bengali/language-model')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner(path / 'BengaliDataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_model(learn.model)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30000, 410])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = encoder.state_dict()['encoder.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 410)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('embeddings_transformer.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.276658</td>\n",
       "      <td>-0.065557</td>\n",
       "      <td>0.176417</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>0.107625</td>\n",
       "      <td>-0.535667</td>\n",
       "      <td>0.161978</td>\n",
       "      <td>-0.063032</td>\n",
       "      <td>-0.295912</td>\n",
       "      <td>0.087943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268345</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>-0.093095</td>\n",
       "      <td>0.129324</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>-0.236765</td>\n",
       "      <td>-0.185207</td>\n",
       "      <td>0.107631</td>\n",
       "      <td>0.181413</td>\n",
       "      <td>0.246582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.109859</td>\n",
       "      <td>0.220141</td>\n",
       "      <td>-0.179959</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>0.104593</td>\n",
       "      <td>-0.087504</td>\n",
       "      <td>0.097410</td>\n",
       "      <td>-0.074559</td>\n",
       "      <td>0.135344</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102015</td>\n",
       "      <td>0.149898</td>\n",
       "      <td>0.317941</td>\n",
       "      <td>-0.005063</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>-0.120756</td>\n",
       "      <td>0.033822</td>\n",
       "      <td>-0.112746</td>\n",
       "      <td>0.053219</td>\n",
       "      <td>0.049918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.110855</td>\n",
       "      <td>0.218759</td>\n",
       "      <td>-0.178260</td>\n",
       "      <td>0.022029</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>0.095522</td>\n",
       "      <td>-0.073796</td>\n",
       "      <td>0.137707</td>\n",
       "      <td>0.147353</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102184</td>\n",
       "      <td>0.151642</td>\n",
       "      <td>0.311132</td>\n",
       "      <td>-0.010139</td>\n",
       "      <td>0.028558</td>\n",
       "      <td>-0.112971</td>\n",
       "      <td>0.038648</td>\n",
       "      <td>-0.116988</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>0.051869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.029481</td>\n",
       "      <td>0.672732</td>\n",
       "      <td>-0.087990</td>\n",
       "      <td>-0.175457</td>\n",
       "      <td>-0.022388</td>\n",
       "      <td>0.421996</td>\n",
       "      <td>0.166604</td>\n",
       "      <td>-0.267720</td>\n",
       "      <td>-0.419014</td>\n",
       "      <td>-0.338803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>-0.358276</td>\n",
       "      <td>-0.396847</td>\n",
       "      <td>-0.134900</td>\n",
       "      <td>-0.174931</td>\n",
       "      <td>-0.392736</td>\n",
       "      <td>-0.230541</td>\n",
       "      <td>-0.195794</td>\n",
       "      <td>0.098930</td>\n",
       "      <td>-0.121982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.186124</td>\n",
       "      <td>-0.297254</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.160423</td>\n",
       "      <td>-0.060533</td>\n",
       "      <td>0.297327</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>-0.102906</td>\n",
       "      <td>-0.290596</td>\n",
       "      <td>-0.176600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152284</td>\n",
       "      <td>-0.301877</td>\n",
       "      <td>0.416140</td>\n",
       "      <td>-0.137230</td>\n",
       "      <td>-0.070624</td>\n",
       "      <td>-0.008602</td>\n",
       "      <td>-0.242522</td>\n",
       "      <td>-0.103611</td>\n",
       "      <td>-0.137982</td>\n",
       "      <td>0.165700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.276658 -0.065557  0.176417  0.029637  0.107625 -0.535667  0.161978   \n",
       "1 -0.109859  0.220141 -0.179959  0.023797  0.104593 -0.087504  0.097410   \n",
       "2 -0.110855  0.218759 -0.178260  0.022029  0.105960 -0.083316  0.095522   \n",
       "3 -0.029481  0.672732 -0.087990 -0.175457 -0.022388  0.421996  0.166604   \n",
       "4 -0.186124 -0.297254  0.006646  0.160423 -0.060533  0.297327  0.115462   \n",
       "\n",
       "        7         8         9    ...       400       401       402       403  \\\n",
       "0 -0.063032 -0.295912  0.087943  ... -0.268345  0.030240 -0.093095  0.129324   \n",
       "1 -0.074559  0.135344  0.139367  ... -0.102015  0.149898  0.317941 -0.005063   \n",
       "2 -0.073796  0.137707  0.147353  ... -0.102184  0.151642  0.311132 -0.010139   \n",
       "3 -0.267720 -0.419014 -0.338803  ...  0.026312 -0.358276 -0.396847 -0.134900   \n",
       "4 -0.102906 -0.290596 -0.176600  ...  0.152284 -0.301877  0.416140 -0.137230   \n",
       "\n",
       "        404       405       406       407       408       409  \n",
       "0  0.064888 -0.236765 -0.185207  0.107631  0.181413  0.246582  \n",
       "1  0.031456 -0.120756  0.033822 -0.112746  0.053219  0.049918  \n",
       "2  0.028558 -0.112971  0.038648 -0.116988  0.055375  0.051869  \n",
       "3 -0.174931 -0.392736 -0.230541 -0.195794  0.098930 -0.121982  \n",
       "4 -0.070624 -0.008602 -0.242522 -0.103611 -0.137982  0.165700  \n",
       "\n",
       "[5 rows x 410 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  <unk>\n",
       "1    <s>\n",
       "2   </s>\n",
       "3      ।\n",
       "4      ,"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('embeddings_transformer_metadata.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0986e-01,  2.2014e-01, -1.7996e-01,  2.3797e-02,  1.0459e-01,\n",
       "        -8.7504e-02,  9.7410e-02, -7.4559e-02,  1.3534e-01,  1.3937e-01,\n",
       "        -2.1156e-04, -1.5727e-02, -2.1426e-01,  7.8057e-02,  2.7946e-02,\n",
       "        -2.3095e-01,  3.6513e-02,  1.0708e-01,  2.3014e-02,  7.2919e-02,\n",
       "        -1.0231e-01, -1.4727e-01, -3.8871e-02,  6.4326e-02, -5.8928e-02,\n",
       "        -1.5694e-01,  1.3051e-01, -1.3630e-01,  2.4261e-01, -2.0171e-03,\n",
       "         1.0705e-01, -8.7649e-02,  2.8304e-02, -4.4801e-01,  4.8569e-01,\n",
       "         8.2242e-02,  1.8289e-01,  1.1505e-01,  6.2897e-02,  1.4264e-02,\n",
       "        -4.3788e-02,  1.0339e-01,  7.2059e-02, -3.6789e-01,  1.1064e-01,\n",
       "        -4.7133e-03, -5.6261e-02, -3.5772e-02, -3.0486e-02,  4.9066e-02,\n",
       "        -1.2123e-01, -1.3859e-02, -2.9171e-01,  8.1506e-02,  2.5879e-01,\n",
       "         8.2652e-02, -1.5609e-01,  1.3121e-01,  1.1510e-01, -1.0480e-01,\n",
       "         6.4789e-01, -9.3769e-03, -1.0541e-01,  3.0571e-01, -6.9436e-02,\n",
       "        -1.7932e-01,  2.7449e-01,  3.8619e-01, -6.1625e-02,  9.7588e-02,\n",
       "        -8.4680e-02, -1.6244e-02, -2.6945e-01,  1.8582e-01, -4.8548e-02,\n",
       "         1.4486e-01, -5.1661e-02, -7.9664e-02, -1.7311e-01, -2.5315e-01,\n",
       "        -1.7479e-01, -8.9550e-02,  4.0736e-02, -2.7520e-01,  7.5698e-02,\n",
       "         1.0197e-02,  2.3640e-02,  1.8552e-02, -1.0045e-01,  2.7892e-02,\n",
       "        -2.5407e-01, -3.4747e-02,  6.0780e-03, -1.0954e-01, -1.4153e-01,\n",
       "         1.9881e-01, -8.0909e-02, -7.9927e-02,  3.2161e-02,  3.0895e-01,\n",
       "         1.1603e-01, -1.6063e-01, -6.0762e-02, -2.4309e-01, -6.6291e-02,\n",
       "         4.5914e-02, -1.4549e-02, -6.6852e-02, -5.5633e-02, -6.6671e-02,\n",
       "         1.4130e-01, -1.8530e-01,  1.2695e-01, -3.0846e-01,  2.6818e-01,\n",
       "        -1.2802e-01, -2.1717e-01,  2.0695e-01,  8.1652e-02, -2.3346e-01,\n",
       "         7.9804e-04, -1.6172e-01,  1.2007e-01, -1.7355e-01, -7.0580e-02,\n",
       "        -3.2556e-01,  1.3252e-01, -1.8949e-02, -1.5231e-01,  6.5419e-02,\n",
       "        -9.9907e-02, -1.0652e-01, -3.1476e-02,  3.4976e-01,  2.2927e-01,\n",
       "        -1.9757e-01,  1.1462e-01,  6.5840e-04,  3.6769e-02, -1.5453e-01,\n",
       "         1.7524e-01, -3.1112e-01, -4.9814e-02,  2.6577e-02, -1.2977e-01,\n",
       "        -3.7613e-01,  4.4271e-02, -7.8530e-02,  4.8883e-02, -9.0956e-02,\n",
       "         4.5797e-02, -1.2969e-01, -1.6405e-01,  7.5359e-02, -1.3288e-01,\n",
       "         2.4702e-01, -2.0006e-01,  5.4215e-02,  1.5615e-01, -1.1394e-01,\n",
       "         1.3383e-01,  2.3493e-01, -2.1877e-01,  3.3018e-01, -1.3090e-01,\n",
       "        -2.7238e-01,  5.9307e-01,  7.6530e-02, -2.0556e-02, -2.4737e-02,\n",
       "        -1.8510e-02,  2.9387e-01,  1.1218e-01,  4.1511e-02, -2.7056e-02,\n",
       "        -1.0255e-01,  2.3430e-01,  3.5550e-01,  8.4670e-02, -4.2774e-01,\n",
       "         1.5644e-01, -7.2553e-02, -1.5909e-01, -4.6082e-02, -1.3618e-01,\n",
       "        -3.0730e-01, -1.6846e-01,  1.8125e-01, -9.3721e-02,  1.6610e-02,\n",
       "         8.4168e-02, -2.0613e-01,  9.8283e-02, -1.4572e-01,  4.9797e-02,\n",
       "        -2.0396e-01,  8.2787e-02,  7.4191e-02,  8.3142e-02,  1.8669e-01,\n",
       "         6.8671e-02,  4.4840e-02,  2.3891e-01,  1.2810e-01, -1.1214e-01,\n",
       "         1.4009e-01, -4.7293e-02,  2.8497e-01, -1.3317e-01, -7.8947e-02,\n",
       "        -2.3778e-01,  1.0338e-01, -9.6381e-03,  1.8028e-01,  2.3767e-01,\n",
       "         1.0339e-01, -9.6029e-02,  1.1342e-01,  7.7145e-02, -1.6318e-01,\n",
       "         1.9394e-01,  8.5783e-02, -1.9841e-01,  4.5227e-02,  4.7401e-02,\n",
       "         6.5933e-02, -7.5364e-02, -5.9838e-02, -6.6547e-03, -1.7479e-01,\n",
       "        -3.2227e-01, -8.5876e-02, -5.7650e-02,  1.4822e-01, -1.4234e-01,\n",
       "        -2.5441e-02,  1.6206e-01, -9.4439e-02,  1.6396e-02, -4.4965e-02,\n",
       "         1.6598e-03,  1.5964e-01, -6.9660e-03, -1.4899e-01, -1.7559e-01,\n",
       "         3.0208e-02, -4.4459e-02,  5.1675e-02, -2.0120e-01, -1.9024e-02,\n",
       "        -1.2609e-01,  1.1652e-01, -4.8546e-01, -3.4227e-02,  1.7982e-01,\n",
       "        -8.1425e-02, -1.0880e-01, -2.3879e-02,  4.1724e-02,  4.4347e-02,\n",
       "         1.2761e-01, -2.7805e-02, -6.8929e-03, -1.4018e-01, -7.9537e-03,\n",
       "        -2.0388e-01,  1.3957e-01, -1.2435e-01, -2.8438e-01, -5.8022e-02,\n",
       "         1.5197e-01,  2.0312e-01,  2.8014e-01,  2.6258e-01, -1.0447e-01,\n",
       "        -8.5523e-02,  1.2670e-01,  8.5653e-02, -3.2514e-02,  1.6728e-01,\n",
       "        -1.6768e-02,  1.6131e-01, -5.8083e-02,  1.9950e-01, -1.4648e-01,\n",
       "        -2.5857e-01, -1.3748e-01, -1.0971e-03, -1.2187e-01, -1.8718e-01,\n",
       "        -1.0528e-01,  1.8067e-01,  6.9962e-03,  1.7346e-01, -1.0897e-01,\n",
       "        -3.0472e-01, -4.0518e-02, -2.6695e-02, -1.3845e-01, -1.6303e-01,\n",
       "         1.6760e-02,  8.6504e-02, -9.5589e-03,  1.7171e-01,  9.5096e-02,\n",
       "         1.8064e-01,  7.4632e-03,  1.4889e-01,  8.8239e-02,  2.2238e-02,\n",
       "         1.0089e-01,  1.6654e-01,  9.2832e-03, -1.3916e-01, -1.2935e-01,\n",
       "         2.2703e-01, -1.5473e-01, -1.6062e-01,  1.0879e-01, -9.2821e-02,\n",
       "        -3.9001e-01, -3.4834e-02,  2.4738e-01, -1.4485e-01, -3.2782e-01,\n",
       "         2.5925e-01, -7.8489e-02,  2.7817e-01, -3.0157e-01,  2.5001e-01,\n",
       "         1.4124e-01, -3.9543e-01,  2.0044e-01,  8.7062e-02, -1.2000e-01,\n",
       "         3.1713e-02, -1.9228e-01, -6.7875e-02, -7.9935e-02, -1.7945e-01,\n",
       "         2.9099e-02, -1.0058e-01,  1.0676e-01,  3.7164e-02, -2.0746e-02,\n",
       "        -3.6423e-02, -4.0745e-02,  1.0210e-01, -1.9355e-01, -1.6262e-01,\n",
       "        -2.8673e-02, -1.6806e-02,  1.6335e-01,  1.6308e-01, -3.1000e-02,\n",
       "        -2.9430e-01, -1.5342e-01, -3.7275e-02,  1.5337e-02, -1.9729e-01,\n",
       "        -1.3388e-01,  3.0661e-01, -1.2899e-01,  1.5274e-01, -2.5929e-01,\n",
       "        -1.4755e-01,  5.9885e-02,  3.8639e-02,  1.7190e-01, -1.6529e-01,\n",
       "        -1.2154e-01, -9.3503e-02, -1.2534e-01, -3.0212e-01,  9.0137e-02,\n",
       "        -5.3237e-02,  2.0633e-02,  3.4118e-02, -1.5398e-01, -5.7820e-02,\n",
       "         9.6202e-02,  1.8969e-01,  5.1964e-02,  2.6785e-01,  1.4130e-01,\n",
       "         9.1499e-02,  2.0858e-01, -3.1634e-01, -1.7746e-01, -1.9400e-01,\n",
       "         9.4550e-03, -3.3413e-02, -6.4221e-02, -1.2843e-01,  4.1054e-02,\n",
       "        -5.3954e-02,  1.8128e-02, -7.8318e-02,  1.4820e-01, -1.0211e-01,\n",
       "        -1.0202e-01,  1.4990e-01,  3.1794e-01, -5.0633e-03,  3.1456e-02,\n",
       "        -1.2076e-01,  3.3822e-02, -1.1275e-01,  5.3219e-02,  4.9918e-02],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict()['encoder.weight'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
